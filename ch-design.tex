%!TEX root =  main.tex
%!TEX encoding = UTF-8 Unicode
\chapter{推薦システム設計の要素}
\label{chap:design}

多種多様な推薦システムのためのアルゴリズムが存在するが，一体，どのアルゴリズムを使えばよいのであろうか？
機械学習の基本的な定理であるノーフリーランチ定理によれば万能アルゴリズムは存在しない．
よって，アルゴリズムは，推薦システムを利用する目的や，推薦を実行する環境の制約に応じて選択する必要がある．
ここでは，そのために考慮すべき要因を大きく二つに分けて述べる．
一つは，推薦の性質である．\ref{sec:recomtask}節の利用者の目的などに応じて，推薦は適切な性質を備えるべきである．この性質を測るための規準を幾つか示す．
もう一つは，推薦を計算するためのデータや計算機資源の制約である．データや計算機資源は無限にはなく，何らかのトレードオフを考慮しつつ推薦システムは設計する必要がある．

\section{推薦の性質}
\label{sec:recomtype}

推薦システムでは，利用者が好むものを予測して提示する．
だが，利用者が何を好むかは，利用者の目的，システムを利用する状況，推薦の候補などによって変化する．
よって，提示する推薦の性質を決めるにあたって考慮すべき規準があれば役立つ．
これらの規準を以下に示す．
なお，推薦の質の評価については，文献\cite{jacm:04:01,jmlr:09:01}が詳しい．
%@@@ 推薦の質の評価の章ができたらそこへリンク
%@@@ 予測精度の評価の章を作ったら，そこに指標の説明を動かす

\subsection{予測精度}
\label{sec:prederr}
\index{予測精度}\index{accuracy}


予測精度とは，予測して推薦したアイテムに，実際にどれくらい利用者が関心をもつかという規準である．
利用者が関心のないアイテムを推薦しても役に立たないので，予測精度は最も重視すべき規準である\cite{sigir:01:01}．
評価はオンラインで行う場合と，オフラインで行う場合がある．
オンラインでの評価とは，被験者に実際にシステムを利用させ，推薦が適合したかどうかを調査するものである．
一方，事前に被験者から集めた嗜好データと，予測した結果の一致を調べるのがオフラインでの評価である．
前者の方がより実際の運用に近い評価ができるが，この調査のコストは高い．そのため，得られるデータ数が少なく安定した検証が困難であったり，多数の項目での比較が困難になるなどの問題がある．
こうした点ではオフラインでの評価の方が有利になる．

オンラインの評価では，それぞれのアルゴリズムを利用させて，推薦を利用者が受け入れる比率で，アルゴリズムの相対的な予測精度を評価する．
また，二つのアルゴリズムによる推薦リストの上位から交互にアイテムを選んで，一つの推薦リストにまとめる．そして，利用者にそれを提示して，どちらのアルゴリズム由来のアイテムがより頻繁に選ばれるかといったことで評価する方法などがある．

オフラインの評価では，一般の機械学習と同様に，交差確認によって汎化誤差を推定し，その汎化誤差で予測精度を評価する．
なお，予測精度の評価については\cite{j:0026}の5章に詳しい．
ここで，アルゴリズムに超パラメータがある場合の注意を述べておく．
超パラメータとは，\ref{sec:user-user}節の方法の近傍の大きさといった，アルゴリズムで調整すべき変数のことをいう．
通常の交差確認では，データを訓練用とテスト用の二つに分けるが，超パラメータがある場合は，厳密には，データを訓練用(training)，確認用 (validation)，およびテスト用(test)の三つに分ける必要がある\cite[7.2節]{e:0022}\cite[1.1節]{e:0028,jpublist:077x}．
そして，アルゴリズムの学習には訓練用データを，超パラメータの決定は確認用データを，そして最終的な予測精度はテスト用データを用いる．
特に，新たに超パラメータを導入したが，予測精度の向上がわずかな場合には，こうした厳密な評価実験をしておくことを薦める．

推薦システムでは，次のような尺度が，テスト用データに対する予測精度の評価に利用されている．
\begin{description}[style=nextline]
 \item[\term{正解率}{accuracy}]
 利用者の関心への適合や不適合が，予測結果とテスト用データで一致した割合を示す．
 評価値を予測するシステムでは5段階のうち上位2段階のいずれかなら適合とみなしたりする．最も基本的な評価指標である．
 \item[\term{精度}{precision}と\term{再現率}{recall}]
 適合判定されたアイテムのうち実際に適合しているものの割合が精度，全ての適合アイテムのうち適合と判定されたものの割合が再現率である\cite{j:0021}．
 適合アイテムを一つ見つければ良い適合アイテム発見タスクでは精度を，全ての適合アイテムを見つけたい適合アイテム列挙タスクでは再現率を重視すべきである．
 情報検索で利用されている，精度や再現率に基づいた，F尺度(F measure)やROC曲線(receiver operating characteristic curve)なども用いられている．
 \item[\term{平均絶対誤差}{Mean Absolute Error}]
 テスト用データの評価値と予測した評価値の差の絶対値のテスト用データ上での平均である\cite{jacm:04:01}．
 評価閲覧タスクでは，適合か不適合かの判定より，評価値そのものを利用者は見る．
 よって，このタスクでは，評価値の予測精度のずれを評価するこの指標を重視すべきである．
 \item[half-life utility metricと順位相関 (rank correlation)]
これらは，推薦するアイテムの並び方の良さを評価する指標である．
計算方法の詳細は文献\cite{jacm:04:01}を参考にされたい．
適合アイテム発見を目的とする場合，推薦システムには意志決定支援の側面が要求される．
このときは，評価値自体よりも，評価の大小を重視すべきである．
これらの指標はこうした場面で有用である．
\end{description}

最後に，推薦システムの予測精度の評価についての問題を指摘しておこう．
交差確認による評価では，テストに使ったサンプルと，今後予測するサンプルは同じ分布から得られることを，通常は仮定している．
詳細は\ref{sec:explicitrating}節で述べるが，評価されていないアイテムは，利用者が関心を示さなかったものであることが多い．
そのため，評価値が欠損するアイテムは，評価が低いアイテムに偏る傾向がある．
こうした原因により，実際にシステムが稼働して予測対象となるアイテムの分布とテストに用いられるアイテムの分布は異なり，厳密に予測精度を評価することは難しい．
そのため，わずかに予測精度を向上させる試みは実用的には利益がないことが多い．
1\%なり3\%ほどの危険率で統計的に有意な差がなければ，ほぼ同等の予測精度とみなし，他の規準を重視して推薦システムを設計すべきである．

\subsection{多様性・セレンディピティ}
\index{多様性}\index{dviersity}
\index{セレンディピティ}\index{serendipity}
%@@@ 多様性の章を作ったらリンク

利用者が関心を持つであろうアイテムを推薦することは推薦システムの目的であり，上記の予測精度はこのことを定量的に評価する．
それに加えて，多くの場合，利用者が知っているアイテムを推薦してもあまり有用ではない．
よって，関心があることに加えて，推薦には，\textbf{目新しさ (novelty)}，すなわち，わかりきったものではないことが要求される．例えば，利用者がスピルバーグ監督のファンであり，この利用者にスピルバーグ監督の新作映画を推薦したとする．このとき，利用者はこの映画に関心をもち，まだ知らない目新しい推薦であり，上記の二つ条件を満たしている．
さらに，要求される条件にセレンディピティの高さがある．推薦における\textbf{セレンディピティ (serendipity)}とは，この目新しさに，思いが
けなさ，予見のできなさ，または意外性の要素が加わった概念である．
例えば，スピルバーグ監督とよく似た作風の新人監督の作品を考える．このとき，作風が似ているため利用者はこの作品に関心をもち，また新規性もある．さらに，利用者はこの新人監督の作風がスピルバーグ監督と似ていることを知らないため，この作品が推薦されることを予見できない，すなわち，意外性がある．よって，この推薦にはセレンディピティがあるといえる．

しかし，このセレンディピティに伴う感情的な応答を定量的に評価することは難しい．
それでも，セレンディピティの一側面ではあるが，それらを定量化する試みもある．
それらの中でも，\term{多様性}{diversity}\cite{misc:033}は，文献\cite{www:05:01}による提案以降多くの研究が行われている．
多様性は，推薦リストに含まれるアイテムが互いに似ていないことである．
あるアイテム間の類似度を決めて，推薦リスト内のアイテム間の類似度を集約することで，多様性は定量的に評価することが多い．
その他，グループ向けの推薦には現れないが個人向けの推薦には現れるもの\cite{jacm:04:01}や，単純な予測器では候補にならないが，高度な予測器では候補になるもの\cite{trjsai:07:03}などをセレンディピティが高いとみなし，こうした仮定に基づいた定量的評価尺度を提案している．

一般に，利用者が推薦を採用したとき，その結果不満だったときのコストは低いが，満足したときの利得は大きい分野では，セレンディピティを重視すべきである．
映画や音楽など娯楽に関する推薦では，こうした状況になることが多い．

\subsection{被覆率}

\term{被覆率}{coverage}とは，全アイテムのうち，評価値の予測が可能なアイテムの割合である．
評価値の予測が不可能な状況には，以下のようなものがある．
協調フィルタリング（\ref{chap:cf}章）では，他の利用者の評価値を利用する．すると，誰にも評価されていないアイテムは評価の対象にできない．
もう一方の内容ベースフィルタリング（\ref{chap:cbf}章）では，アイテムの特徴量が欠損していたり，利用者のプロファイルが未整備である場合には，評価値を予測できない．
適合アイテム発見タスクでは，利用者が満足するものが何か見つかれば良いので被覆率は比較的低くても問題は生じない．
評価閲覧が目的なら，評価値のないアイテムが多数あるのは不便なので被覆率は高くあるべきである．
適合アイテム列挙タスクでは，推薦すべき対象の見落としは許されないので，基本的に被覆率は100\%でなければならない．

\subsection{学習率}

嗜好データの増加に伴って予測精度は向上するが，その向上の度合いを\term{学習率}{learning rate}と呼ぶ．これは，実用的な予測精度に達するまでに必要な嗜好データの数で決まる．
システム全体を評価する学習率は，嗜好データの総数から計算するが，特定のアイテムや利用者に限定した評価をするための学習率も用いられる．
学習率を調整するパラメータをもつアルゴリズムも多いが，学習率を高くしすぎると過学習のため汎化誤差が悪化して，予測精度の向上が不十分なレベルで止まる場合もある．
しかし，利用者が評価付けをあまりしない場合や，服飾品など商品のサイクルの早いアイテムでは，過学習の危険性があっても学習率はやや高くすべきである．

\subsection{推薦の性質に関するトレードオフ}

言うまでもなく，正解率やセレンディピティなど上記の規準で全て良いものが理想的な推薦システムである．
しかし，これらの評価規準は，次に挙げるようなトレードオフの関係にあり，目的に応じてバランスをとる必要がある．
予測精度は，推薦において最も重要な規準だが，これだけでは不十分であることは十分に注意すべきである．
文献\cite{sigchi:03:02}には，利用者は5段階評価で1段階良く，もしくは悪く改竄した推薦を見せられると，そのことに利用者は気づき，このような改竄システムへの利用者の満足は低いことが報告されている．
よって，予測精度は，利用者の満足に影響していることは確かである．
だが，計測した予測精度が同じシステムでも，利用者の満足には大きなばらつきがあるとも，この文献は報告している．
ほとんどの利用者が好むであろう限られたものだけを推薦すれば，予測精度は一般に高くなる．
例えば，スーパーマーケットでの買い物で牛乳や卵など，ほとんどの顧客が購入する商品を推薦すると，予測精度の観点からは良い推薦である．
だが，当たり前すぎて目新しさはなく，一概に良い推薦とはいえない．
新たにシステムを利用し始めた利用者には，システムへの信頼を高めるために，予測精度を重視して確実に好まれるものを推薦する方が良い．
予測精度の評価指標は，評価値を計算できなかったアイテムは無視して計算するのが一般的である．
そのため，嗜好データが十分なアイテムだけを推薦対象にすれば，予測精度は向上するが，被覆率は下がってしまう．
また，学習率の向上も過学習などの影響で，予測精度を低下させる場合がある．
以上のように複雑なトレードオフの関係があるため，どの指標を，どのようなバランスで重視するかは，推薦対象や，利用者の目的など多くの要因を考慮して決めなければ，利用者の満足を得られるような推薦システムは設計できない\cite{sigchi:06:01}．

こうした設計を組織的に行うための研究もいくつかある．
文献\cite{sigchi:06:02}では，Human-Recommender Interaction (HRI) \index{human-recommender interaction}というモデルを提案している．これは，システムと人間のやりとりである推薦ダイアログ (recommendation dialogue)，推薦の傾向を表す推薦器の個性 (recommender personality)，および利用者情報探索タスク (user information seeking task)の三つ点について，それぞれの特徴を記述するための規準を定めている．
この規準に基づき，利用者の推薦への要求や，推薦アルゴリズムの特徴を記述し，目的に応じて適切な対応付けをするHRI解析プロセスモデルを提唱している．

\section{推薦候補の予測に関する制約}
\label{sec:rsyslimit}

推薦候補を予測するために必要な，データや計算機資源は無限にはなく，何らかのトレードオフを考慮しつつ推薦アルゴリズムを選択する必要がある．
よって，これらの制約や条件についてまとめる．

\subsection{嗜好データの制約}

嗜好データの最も顕著な特徴は非常に\term{疎}{sparse}であることである．
すなわち，非常に多くのアイテムが存在するが，利用者が評価しているのはごく一部で，その他のアイテムへの評価値は欠損している．
具体的には，評価値があるのは全体の1\%〜0.001\%のオーダである\cite{dmkd:01:01}．
また，欠損は均一ではなく，Zipfの法則\cite{j:0021}のように，被評価数の順に，被評価数ごとのアイテム数を整列すると，被評価アイテム数は指数的に減少する現象がみられる\cite{misc:007}．
こうした疎なデータからの予測は困難である．
また，詳しくは\ref{sec:explicitrating}節で述べるが，嗜好の評価値は，統制されていない環境で採取された心理的な量なので，揺らぎが大きく，評価のたびに変化して不整合を生じる問題もある．
あと，利用者数とアイテム数の比率は予測精度に影響する\cite{jacm:04:01}ので，実際の運用状況に合わせてテストをすべきである．
最後に嗜好データの更新の問題がある．
推薦システムは運用中に，随時嗜好データが追加される．また，新たに利用者やアイテムがデータベースに追加されることもある．
こうした変化に応じて予測モデルを更新する必要がある．
平滑化などを用いた予測技術を使うと，疎なデータでも比較的安定的な予測ができるが，計算量が増えて予測モデルの更新を頻繁に実行できず，これらの変化に対応できなくなるといった問題もある．

\subsection{その他の制約や条件}

データ数が多数であるにもかかわらず，高速な予測が要求されるスケーラビリティは重要な問題である．
利用者数は 10万〜100万，アイテム数は 10〜100万，利用者あたりの評価数 10〜1000 という大規模なデータにもかかわらず，10〜1000の要求に対して，10〜100ミリ秒の時間で応答することが要求される~\cite{dmkd:01:01,ieeem:03:01}．
このような高いスケーラビリティを達成しつつ，正確に予測することも困難な課題である．

他に，推薦を利用する状況の問題もある．例えば，レストランの推薦システムでは，一人で食べに行く場合と，家族で食べに行く場合は異
なった推薦をすべきだろう．
こうした推薦をする状況や利用者の暗黙的な要求を考慮するかどうかは大きな要因となる．
また，利用者がどれくらい詳細な推薦を求めているかも，アルゴリズムを選択するときに考慮すべき事柄である．
すなわち，利用者の嗜好に適合か不適合の2段階程度の大まかなものでよいのか，購入のための意志決定のため，いろいろな評価項目について利用者の嗜好への適合度を詳細に要求するのかといった違いである．
